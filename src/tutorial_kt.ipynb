{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../data/transformed_data.csv')\n",
    "df_val = pd.read_csv(r'../data/transformed_2020_data.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['StateCode'])\n",
    "\n",
    "X = df.drop(columns=['TotalAmountofAssistance']).values\n",
    "y = df['TotalAmountofAssistance'].values\n",
    "X[:, 0] = label_encoder.transform(X[:, 0])\n",
    "\n",
    "\n",
    "X_val = df_val.drop(columns=['TotalAmountofAssistance']).values\n",
    "y_val = df_val['TotalAmountofAssistance'].values\n",
    "X_val[:, 0] = label_encoder.transform(X_val[:, 0])\n",
    "\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "y_val = y_val.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu', input_shape=[X.shape[1]]))\n",
    "  model.add(keras.layers.Dense(1, activation='linear'))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.metrics.RootMeanSquaredError(),\n",
    "                metrics=keras.metrics.RootMeanSquaredError())\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from my_dir\\intro_to_kt\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<keras_tuner.engine.trial.Trial object at 0x00000182655DFEB0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[stop_early])\n\u001b[0;32m      3\u001b[0m \u001b[39m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[0;32m      4\u001b[0m best_hps\u001b[39m=\u001b[39mtuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\danie\\Projects\\chevron_investment\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:200\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_create_trial()\n\u001b[1;32m--> 200\u001b[0m     trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mcreate_trial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner_id)\n\u001b[0;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m trial\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mSTOPPED:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# Oracle triggered exit.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         tf\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mOracle triggered exit\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\Projects\\chevron_investment\\venv\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:104\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m     LOCKS[oracle]\u001b[39m.\u001b[39macquire()\n\u001b[0;32m    103\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m thread_name\n\u001b[1;32m--> 104\u001b[0m ret_val \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m need_acquire:\n\u001b[0;32m    106\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\Projects\\chevron_investment\\venv\\lib\\site-packages\\keras_tuner\\engine\\oracle.py:302\u001b[0m, in \u001b[0;36mOracle.create_trial\u001b[1;34m(self, tuner_id)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m# Pick the Trials waiting for retry first.\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_queue) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 302\u001b[0m     trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrials[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_queue\u001b[39m.\u001b[39;49mpop()]\n\u001b[0;32m    303\u001b[0m     trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    304\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mongoing_trials[tuner_id] \u001b[39m=\u001b[39m trial\n",
      "\u001b[1;31mKeyError\u001b[0m: <keras_tuner.engine.trial.Trial object at 0x00000182655DFEB0>"
     ]
    }
   ],
   "source": [
    "tuner.search(X, y, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f44817b5562e7e0b11fcb3564e2c72dc1905b564c23afc95288e9b9927cb9b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
